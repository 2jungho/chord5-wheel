<!DOCTYPE html>
<html>
  <head>
    <base href="/" />

    <meta charset="UTF-8" />
    <meta content="IE=Edge" http-equiv="X-UA-Compatible" />
    <meta name="description" content="A new Flutter project." />

    <!-- iOS meta tags & icons -->
    <meta name="mobile-web-app-capable" content="yes" />
    <!-- Fix for deprecation warning -->
    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black" />
    <meta name="apple-mobile-web-app-title" content="guitar_theory_app" />
    <link rel="apple-touch-icon" href="icons/Icon-192.png" />

    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="favicon.ico" />

    <title>Chord Progression Studio</title>
    <link rel="manifest" href="manifest.json" />
    <meta name="theme-color" content="#0f172a" />

    <!-- Add Tone.js for Web Audio -->
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.7.77/Tone.js"
      crossorigin="anonymous"
    ></script>
    <!-- Cache control for PWA updates -->
    <meta
      http-equiv="Cache-Control"
      content="no-cache, no-store, must-revalidate"
    />
    <meta http-equiv="Pragma" content="no-cache" />
    <meta http-equiv="Expires" content="0" />
  </head>
  <body>
    <!-- Dynamically load flutter.js with cache busting -->
    <!-- Flutter bootstrap -->
    <script>
      console.log("Web Audio Engine Initializing - v8 (Rhythm Support)");

      let sampler;
      let isLoaded = false;
      let currentInstrument = "guitar_std";

      window.setWebInstrument = function (id) {
        currentInstrument = id;
        console.log("Web Audio: Instrument set to " + id);
      };

      sampler = new Tone.Sampler({
        urls: {
          E2: "assets/assets/sounds/E2.mp3",
          A2: "assets/assets/sounds/A2.mp3",
          D3: "assets/assets/sounds/D3.mp3",
          G3: "assets/assets/sounds/G3.mp3",
          B3: "assets/assets/sounds/B3.mp3",
          E4: "assets/assets/sounds/E4.mp3",
          A3: "assets/assets/sounds/A3.mp3",
          C3: "assets/assets/sounds/C3.mp3",
          E3: "assets/assets/sounds/E3.mp3",
          G2: "assets/assets/sounds/G2.mp3",
        },
        baseUrl: "./",
        onload: () => {
          console.log("Guitar samples mapping completed!");
          isLoaded = true;
        },
      }).toDestination();

      window.playWebGuitarNote = function (note, octave) {
        if (!isLoaded) return;
        if (Tone.context.state !== "running") {
          Tone.start();
        }

        // Bass Simulation: Shift down 1 octave
        // Tone.Sampler will improved repitch available samples (e.g. E2 -> E1 = 0.5x speed)
        let targetOctave = octave;
        if (currentInstrument.includes("bass")) {
          targetOctave -= 1;
        }

        sampler.triggerAttackRelease(note + targetOctave, "2n");
      };

      window.scheduleWebSequence = async function (bpm, dataJson) {
        if (!isLoaded) return;
        await Tone.start();
        Tone.Transport.stop();
        Tone.Transport.cancel();
        Tone.Transport.bpm.value = bpm;

        const data = JSON.parse(dataJson);
        const progression = data.progression;
        const rhythm = data.rhythm;

        let currentBeat = 0; // Cumulative beats

        progression.forEach((block) => {
          const notes = block.chordDetail ? block.chordDetail.notes : [];
          if (notes.length === 0) {
            currentBeat += block.duration;
            return;
          }

          const barsInBlock = block.duration / 4;
          for (let b = 0; b < barsInBlock; b++) {
            const barStartBeat = currentBeat + b * 4;

            rhythm.steps.forEach((step) => {
              // pos 0-15 mapped to a 4-beat bar
              // 1 step = 0.25 beats (16th note)
              const offsetBeats = step.pos * 0.25;
              const absoluteBeat = barStartBeat + offsetBeats;

              // Use Tone.Time to convert beats to seconds accurately
              const startTime = Tone.Time(absoluteBeat, "n").toSeconds();

              Tone.Transport.schedule((time) => {
                const velocity = step.accent ? 0.8 : 0.5;

                if (step.type === "down" || step.type === "up") {
                  notes.forEach((note, i) => {
                    // Strum delay: ~20ms per string
                    const strumDelay =
                      step.type === "down"
                        ? i * 0.02
                        : (notes.length - 1 - i) * 0.015;
                    sampler.triggerAttackRelease(
                      note + "3",
                      "4n",
                      time + strumDelay,
                      velocity
                    );
                  });
                } else if (step.type === "bass") {
                  sampler.triggerAttackRelease(
                    notes[0] + "2",
                    "4n",
                    time,
                    velocity + 0.1
                  );
                } else if (step.type === "mute") {
                  notes.forEach((note, i) => {
                    sampler.triggerAttackRelease(
                      note + "3",
                      "16n",
                      time + i * 0.01,
                      velocity * 0.4
                    );
                  });
                }
              }, startTime);
            });
          }
          currentBeat += block.duration;
        });

        // Loop the progression
        Tone.Transport.loop = true;
        Tone.Transport.loopEnd = currentBeat + "n";
        Tone.Transport.start();
      };

      window.stopWebAudio = function () {
        Tone.Transport.stop();
        Tone.Transport.cancel();
      };

      window.setWebBPM = function (bpm) {
        Tone.Transport.bpm.value = bpm;
      };
    </script>
    <script src="flutter_bootstrap.js" async></script>
  </body>
</html>
